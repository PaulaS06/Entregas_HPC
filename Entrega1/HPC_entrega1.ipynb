{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">High Performance Computing</h3>\n",
    "<h3 align=\"center\">Computación de Alto Desempeño</h3>\n",
    "<h3 align=\"center\">Entrega 1 - Conceptos de HPC y Computación Paralela</h3>\n",
    "<h3 align=\"center\">Marzo - 2025</h3>\n",
    "<h3 align=\"center\">Universidad de Medellín </h3>\n",
    "<h5 align=\"center\">Paula S. Meneses Gasca </h5>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La computación científica ha sido reconocida como el tercer enfoque del descubrimiento científico, complementando la experimentación y la teoría. Aunque la informática ha evolucionado hacia múltiples áreas, la computación científica sigue siendo fundamental para la innovación y el desarrollo tecnológico.\n",
    "\n",
    "Uno de los avances más relevantes en este campo es la computación de alto rendimiento (HPC, por sus siglas en inglés), una tecnología que permite realizar cálculos complejos de manera más eficiente y en menos tiempo. Esto se logra mediante el uso de múltiples procesadores que trabajan en paralelo para procesar grandes volúmenes de datos, lo que es especialmente útil en el análisis de Big Data y en la resolución de problemas complejos. \n",
    "*<center>\n",
    "“Los sistemas HPC suelen funcionar a velocidades más de un millón de veces más rápidas que los sistemas más rápidos de escritorio, portátiles o servidores.”\n",
    "(IBM, s.f.)</center>*\n",
    "\n",
    "Durante los últimos 20 años, el desarrollo de la computación científica ha estado impulsado por el procesamiento en paralelo, una técnica clave en la modelización y simulación computacional. La computación de alto rendimiento sigue evolucionando con la incorporación de nuevas tecnologías como las unidades de procesamiento gráfico (GPU), los circuitos FPGA y la computación cuántica, lo que plantea nuevas oportunidades y desafíos.\n",
    "\n",
    "El cómputo paralelo, base del HPC, consiste en dividir un problema en varias partes que pueden resolverse simultáneamente mediante múltiples unidades de procesamiento (PU). Es decir, un problema se descompone en N subproblemas, donde N suele ser el número de PU disponibles, y cada subproblema se ejecuta en paralelo.\n",
    "\n",
    "Para aprovechar el paralelismo de manera eficiente, es fundamental evaluar la viabilidad de la estrategia computacional antes de su implementación. Una mala distribución de las tareas o un diseño inadecuado pueden generar ineficiencias y desperdiciar recursos computacionales. Por ello, la correcta planificación y optimización de la computación paralela es un aspecto clave en el desarrollo de soluciones de alto rendimiento[3].\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tTener claro las definiciones, arquitecturas, tendencias, y demás conceptos básicos de la Computación de Alto Desempeño para poder establecer su impacto en la ciencia y la ingeniería. \n",
    "2.\tIdentificar los principales enfoques arquitectónicos de los sistemas de Computación de Alto Desempeño, entender sus diferencias para tener claro cual es el más eficiente, el más utilizado o entender el conexto en el que se debe tener. \n",
    "3.\tProfundizar en temas como Big data, las IAs, machine learning, para identificar el impacto que tiene la Computación de Alto Desempeño en estas áreas. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptos Fundamentales de HPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paralelismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un algoritmo secuencial en una computadora estándar ejecuta las instrucciones de manera secuencial, es decir que cada tarea sucede después de que la computadora completa la directamente anterior, sin embargo, HPC se encarga de utilizar los procesadores disponibles para realizar varias tareas al mismo tiempo, por lo que el tiempo se reduce en grandes cantidades; sin embargo es necesario tener claro que no todos los problemas pueden ser solucionados de manera secuencial, esto depende de las tareas que se tengan que realizar, la manera en la que se tienen que recibir la información y el orden inicial de las tareas. \n",
    "\n",
    "Normalmente el HPC se realiza en supercomputadoras, computadoras de alto rendimiento que procesa datos a velocidades muy altas, sin embargo el paralelismo se puede realizar en una computadora de uso personal, haciendo uso de varios de sus núcleos o procesadores [4]. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\t**Memoria compartida:** Es una arquitectura en la cual, todos los procesadores acceden a una misma memoria común. Este tipo de arquitectura permite al programador concentrarse en la mejor forma de paralelizar, pudiéndose enfocar en la sincronización y comunicación de los procesos. \n",
    "\n",
    "    La evolución de la tecnología ha permitido que un solo dispositivo contenga varios núcleos o CPUs, por lo que se puede cumplir la memoria compartida donde varios procesadores en un mismo dispositivo, comparten memoria [5].\n",
    "\n",
    "    La memoria compartida puede presentar 2 casos, el primero es el acceso uniforme a la memoria (UAM), que se caracteriza por tener procesadores idénticos que pueden acceder de igual manera y en el mismo momento a la memoria, es decir todos los procesadores se enteran si hay alguna actualización en la memoria. Por otro lado el acceso no uniforme a la memoria (NUMA), donde No todos los procesadores poseen el mismo tiempo de acceso a las memorias.\n",
    "\n",
    "-\t**Memoria distribuida:** Es una arquitectura en la cual, cada procesador tiene su propia memoria y se comunica con otros  por medio del MPI, Message Passing Interface.\n",
    "\n",
    "    En esta los procesos que están siendo ejecutados en las computadoras, deben enviar y recibir información por medio de mensajes. MPI es un estándar que prioriza las comunicaciones punto a punto y tiene en cuenta el contexto de la comunicación [5]. \n",
    "\n",
    "    En esta, los procesadores tienen su propia memoria local que funciona de manera independiente, por lo que los cambios en esta no actualizan las demás memorias, es decir, los demás procesadores no tiene acceso a esta. La transferencia de datos e información normalmente se realiza por conexiones de “Ethernet”.\n",
    "\n",
    "-\t**Memoria hibrida (distribuida/compartida):**  es una mezcla entre la memoria distribuida y compartida. Utiliza máquinas de memoria compartida con unidades de procesamiento gráfico (GPU), sin embargo la interconexión de estas es por medio de comunicaciones de red para transferir datos de una máquina a otra. Son maquinas que solo conocen su propia memoria, no tienen acceso a la memoria de otra [6]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computadora de programa almacenado o Arquitectura de computadoras de Von Neumann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las  instrucciones y datos del programa se guardan en una memoria electrónica y no mediante \"cableado físico\".\n",
    "\n",
    "Estas computadoras cuentan con una estructura básica que consta de 4 componentes: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\t**Memoria:** es el dispositivo que retiene, memoriza o almacena datos informáticos durante un periodo de tiempo.\n",
    "2.\t**Unidad de control:** circuito que controla el flujo de datos y las operaciones de un ordenador (instrucciones y datos). \n",
    "Decodifica las instrucciones y luego coordina secuencialmente las operaciones para realizar la tarea.\n",
    "3.\t**Unidad aritmética lógica:** se encarga de realizar operaciones matemáticas básicas y lógicas transmitiendo señales en 0 y 1 (binarios).\n",
    "4.\t**Entrada/Salida:** se refiere a la entrada y salida de la data, relacionada directamente con el humano. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características principales: \n",
    "-\tLa memoria de acceso almacena instrucciones y datos. \n",
    "-\tInstrucciones: datos codificados que le dicen a la computadora lo que hay que hacer. \n",
    "-\tDatos (data): información que utiliza el programa. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomía clásica de Flynn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasifica las arquitecturas dependiendo del flujo de instrucciones y flujo de datos, teniendo un estado único o múltiple. \n",
    "\n",
    "La siguiente matriz muestra la clasificación según esta taxonomía. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "  <tr>\n",
    "    <td> <center><b>SISD</b></center> <br>\n",
    "        Única instrucción <br>\n",
    "        Único dato\n",
    "    </td>\n",
    "    <td><center><b>SIMD</b></center><br>\n",
    "        Única  instrucción <br>\n",
    "        Múltiples datos \n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center><b>MISD</b></center> <br>\n",
    "        Múltiples instrucciones  <br>\n",
    "        Único dato\n",
    "    </td>\n",
    "    <td><center><b>MIMD</b></center><br>\n",
    "        Múltiples instrucciones <br>\n",
    "        Múltiples datos\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrucción única, datos únicos (SISD):** se da en una computadora serial, solo se utiliza un flujo de datos y solo se ejecuta una instrucción. Por ejemplo una computadora con un solo núcleo. \n",
    "\n",
    "**Instrucción única, datos múltiples (SIMD):** se da en una computadora paralela, todas las unidades ejecutan la misma instrucción, sin embargo, cada una puede tener un flujo de datos diferente. \n",
    "\n",
    "**Instrucciones múltiples, datos únicos (MISD):** se da en una computadora paralela, cada unidad tiene flujos diferentes de instrucciones pero manejan el mismo flujo de datos. \n",
    "\n",
    "**Múltiples instrucciones, múltiples datos (MIMD):** se da en una computadora paralela, cada unidad tiene flujos diferentes de instrucciones y manejan flujos de datos independientes. \n",
    "\n",
    "Este último es el utilizado por las famosas supercomputadoras utilizadas para el paralelismo [6]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
